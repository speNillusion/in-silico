Você é um gerador de código Python profissional. Gere um repositório mínimo com os arquivos e conteúdo listados abaixo. Requisitos importantes (não-negociáveis):

Não fornecer nunca protocolos de laboratório, instruções de cultivo, manipulação de fungos, ou qualquer operação de biossegurança. Apenas soluções computacionais (in-silico), orquestração, análise e priorização. Em texto de saída comente claramente o aviso de segurança.

O código deve usar Python 3.10+, ser tipado (type hints), conter docstrings (reST ou Google style) e logging. Use dotenv para variáveis sensíveis.

Use a biblioteca google.generativeai (SDK da Gemini) para tarefas de linguagem/visão conforme o protótipo fornecido e encapsule chamadas à Gemini em uma classe/módulo claramente separada (facilitar testes/mocks).

Inclua tratamento de erros robusto e mensagens claras ao usuário.

Forneça um único arquivo principal prototype.py com módulos organizados (pode usar seções no mesmo arquivo ou importar arquivos auxiliares, mas entregue todo o conteúdo).

Forneça também requirements.txt, README.md e um pequeno tests/test_pipeline.py com pytest que verifica funções críticas com mocks (não chame a Gemini real durante testes — use mocking).

Inclua exemplos de uso (CLI simples: python prototype.py --analyze-images ... e python prototype.py --run-sim --dataset sample.csv).

Objetivo do código a ser gerado

Gere um protótipo computacional que:

Forneça uma classe GeminiClient que encapsula:

autenticação via GOOGLE_API_KEY (lido do .env),

métodos para generate_text(prompt: str, **kwargs) -> str e analyze_images(image_paths: List[str], prompt: str) -> str.

interface para visão: aceitar objetos PIL.Image.Image ou caminhos de imagem.

Forneça uma classe Pipeline que implementa o fluxo simplificado:

ingest_sources() — funções stub para buscar/normalizar metadados (ex.: ler CSV local, placeholder para API da NASA / UniProt — documente onde inserir API calls).

feature_engineering(candidates: pd.DataFrame) -> pd.DataFrame — gere features demonstrativas (ex.: amino_acid_composition, length, env_temp_mean) usando Biopython quando aplicável; se Biopython não estiver disponível, use funções simples que extraem composition a partir de sequência.

train_surrogate(features, labels) — treine um modelo simples (ex.: LightGBM ou RandomForest) com scikit-learn; forneça opção use_mock=True para criar um modelo dummy quando dados não existirem.

predict_with_uncertainty(model, X) — retornar média e incerteza (utilize ensemble simples ou sklearn.ensemble + std dev).

acquisition_function(preds_mean, preds_std, k=5) -> List[int] — selecione top-k candidatos (ex.: Expected Improvement approximation).

generate_report(candidates, scores, out_path) — salve CSV e um relatório simples em Markdown.

Inclua a função de análise de imagens integrada ao protótipo usando o GeminiClient:

Função: analyze_plastic_degradation(image_paths: List[str]) -> str — usa a API de visão do Gemini para pedir análise temporal das imagens e retorna texto com seções: avaliação, taxa estimada (se possível), mudanças visíveis, recomendações computacionais.

No caso de falta de chave/API, retorne resposta simulada e explique que é um stub de demonstração.

Forneça um agente simples (classe AgentOrchestrator) que:

Orquestra ingestion → features → surrogate → acquisition → relatório.

Mantém um registro (logging) de decisões e reasons (por que um candidato foi priorizado).

Permite re-treinar com novos dados (simulado).

Forneça CLI e exemplos:

--sample-run cria um dataset sintético (10 candidatos) e executa pipeline completo, salvando output/report.md e output/top_candidates.csv.

--analyze-images path1 path2 ... chama analyze_plastic_degradation e imprime/salva resultado.

Forneça instrumentos de observabilidade:

Logging (INFO / DEBUG) e métricas simples (número de candidatos, top score).

Estrutura mínima para integrar MLflow/W&B (comentários com placeholders).

Forneça tests:

tests/test_pipeline.py que testa: geração de dataset sintético, feature_engineering produz colunas esperadas, acquisition_function retorna exatamente k IDs, analyze_plastic_degradation lida com imagens inexistentes (mock) sem lançar exceção.

Use pytest e unittest.mock para simular respostas do GeminiClient.

Arquivos adicionais:

requirements.txt com libs mínimas: google-generativeai, python-dotenv, Pillow, pandas, scikit-learn, lightgbm (opcional), pytest.

README.md com instruções de uso, aviso de biossegurança (não executar nem replicar protocolos de laboratório), e exemplos de comandos.

Estilo de código / convenções

PEP8, docstrings, type hints.

Funções curtas (máx ~120 linhas).

Exponha pontos onde o usuário deve inserir suas chaves/API endpoints (com comentários).

Evite chamadas de rede reais em testes — use env var CI=true ou USE_MOCKS=true para rodar em modo offline.

Ao gerar texto explicativo no relatório, cite apenas fontes públicas (indicar placeholders onde inserir referências) mas não faça scraping automático sem autorização.

Exemplo de entrada/execução esperada

.env:

GOOGLE_API_KEY=your_key_here
USE_MOCKS=true


Executar exemplo:

python prototype.py --sample-run
python prototype.py --analyze-images samples/img1.jpg samples/img2.jpg samples/img3.jpg
python -m pytest -q


O output deve incluir:

output/report.md (resumo do pipeline + top candidates + justificativa)

output/top_candidates.csv

logs em console

Conteúdo final pedido ao modelo (o que o modelo deve devolver)

Imprima apenas (1) o conteúdo completo do arquivo prototype.py, seguido por (2) requirements.txt, (3) README.md e (4) tests/test_pipeline.py. Use separadores claros entre arquivos (por exemplo === prototype.py ===).

Não entregue credenciais reais.

Se alguma dependência não puder ser importada no ambiente do usuário, o código deve detectar e oferecer um modo fallback (modo mock).

Inclua comentários no código que expliquem pontos onde integrar dados reais (APIs NASA, UniProt, PDB, AlphaFold).

Observação final (para inserir no topo do código gerado)

Insira um bloco de comentário no topo do prototype.py com o seguinte aviso:

AVISO DE SEGURANÇA: Este projeto é apenas computacional. Não contém instruções de laboratório nem protocolos para manipulação de organismos. Não tente realizar procedimentos de cultura, manipulação ou liberação de microrganismos com base neste código. Consulte sempre especialistas e normas de biossegurança.

Se quiser, gere agora o código com esse Super Prompt. Se preferir, eu mesmo gero um prototype.py completo agora com base no seu protótipo e blueprint — diga apenas “gere o código” e eu crio tudo já com os arquivos e testes.